<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Guangwei Gao</title>
    <base href="https://guangweigao.github.io/">
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Guangwei Gao (高广谓)</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
	<!-- <div class="menu-item"><a href="news.html">News</a></div> -->
        <!--<div class="menu-item"><a href="education.html">Education</a></div>-->
	<!-- <div class="menu-item"><a href="contact.html">Contact (联系方式)</a></div> -->
	<div class="menu-item"><a href="publications.html">Publications</a></div>
	<div class="menu-item"><a href="patents.html">Patents</a></div>
	<div class="menu-item"><a href="service.html">Services</a></div>
	<!--<div class="menu-item"><a href="codes.html">Codes</a></div>-->
	    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="awardstalks.html">Awards & Talks</a></div>
    <!--<div class="menu-item"><a href="talks.html">Talks</a></div>-->
	<div class="menu-item"><a href="members.html">Group Members</a></div>
	<div class="menu-item"><a href="projects.html">Research Projects</a></div>
	<div class="menu-item"><a href="recruitement.html">Call for Students</a></div>
	<div class="menu-item"><a href="resources.html">Recommended Resources</a></div>
	<div class="menu-item"><a href="icme22ss.html">ICME2022 Special Session</a></div>
    <!--<div class="menu-item"><a href="codedata.html">Codes & Data</a></div>
    <!--<div class="menu-item"><a href="seminar.html">ML Seminar</a></div>-->
	<!--<span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>-->
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Welcome to the Intelligent Visual Information Perception Laboratory (IVIPLab) !</h1><br>
  <!--  <p>[ <a href="#news">News</a>,
        <a href="#interest">Research Interests</a>,
        <a href="#job">Job Experience</a>,
        <a href="#edu">Education</a> ]</p>-->

    <table class="imgtable"><tr valign="top">
        <td><img src="imgjpg/myphoto.jpg" alt="MyPhoto" /></td>
        <td align="left">
            <p><span style="font-size: 110%"><b>Guangwei Gao</b></span></p>
            <p>
                Associate Professor <br>
		Institute of Advanced Technology<br>
		Nanjing University of posts and Telecommunications<br>
		No.9, Wenyuan Road, Xianlin, Nanjing, China, 210046<br>
		<!--Postdoc Fellow (with <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a>)<br>
                <a href="https://aip.riken.jp/labs/generic_tech/imperfect_inf_learn/" target="_blank">Imperfect Information Learning Team</a><br>
                <a href="http://www.riken.jp/en/" target="_blank">RIKEN</a>
                <a href="https://aip.riken.jp/" target="_blank">Center for Advanced Intelligence Project</a> -->
            </p>
             <!--<p>
                Assistant Professor<br>
                <a href="https://www.comp.hkbu.edu.hk/v1/?page=home" target="_blank">Department of Computer Science</a><br>
                <a href="https://www.hkbu.edu.hk/eng/main/index.jsp" target="_blank">Hong Kong Baptist University</a>
            </p> -->

                E-mail:  <i><b>csggao@gmail.com</b></i> (commonly used) & <i>csgwgao@njupt.edu.cn</i><br>
                <!--<a href="https://sites.google.com/view/guangweigao">[Google Web]</a>-->
                <a href="https://github.com/guangweigao">[Personal Github]</a> 
		<a href="https://github.com/IVIPLab">[IVIPLab Github]</a>
		<a href="https://scholar.google.com/citations?user=YD6gAw4AAAAJ&hl=zh-CN">[Google Scholar]</a> 
		<a href="https://dblp.org/pid/118/3484.html">[DBLP]</a> 
				<br>
               
            </p>			 
				
		
        </td>
    </tr></table>
	
	
	
	<div>
        <h2><hr><a name="Research topics"></a>Research Topics</h2>
        <ul>
           My research interests lie in machine learning, pattern recognition, and learning-based vision problems. Particularly, I'm interested in heterogeneous face image analysis (recognition, super-resolution), lightweight deep neural network design (used for semantic segmentation, super-resolution), analysis and processing of cross-modality visual data. <br>  
        </ul>			 
    </div>
	
	
	<div>
        <h2><hr><a name="Education"></a>Education</h2>
        <ul>
              <li><p>09/2005-07/2009,  School of Math and Computer Science and Engineering, Nanjing Normal University, 
                  B.S. in Information and Computation Science</p></li>
              <li><p>09/2009-06/2014,  School of Computer Science and Engineering, Nanjing University of Science and Technology, Ph.D. in Pattern Recognition and Intelligence Systems, supervised by Prof. <a href="http://www.patternrecognition.asia/jian/"><i><b>Jian Yang</b></i></a></p></li>
              <li><p>03/2011-09/2011, 02/2013-08/2013, Visiting Student,  Depatment of Computing, The Hong Kong Polytechnic University, supervised by Prof. <a href="https://www4.comp.polyu.edu.hk/~cslzhang/"><i><b>Lei Zhang</b></i></a></p></li>
</ul>
  </div>	
	
	
	<div>
        <h2><hr><a name="Research Experience"></a>Research Experience</h2>
        <ul>
		<li><p> 11/2014- 11/2016, Postdoctoral Researcher, Nanjing University of Posts and Telecommunications </p></li>
		<li><p> 07/2014-06/2017, Assistant Professor, Institute of Advanced Technology, 
	Nanjing University of Posts and Telecommunications</p></li>
		<li><p> 07/2017-present, Associate Professor, Institute of Advanced Technology, 
	Nanjing University of Posts and Telecommunications</p></li>
                <li><p> 04/2019-03/2021, Project Researcher, National Institute of Informatics, Tokyo, Japan</p></li>	
        </ul>
    </div>
	
	
	
 <div>
        <h2><hr><a name="news"></a>Recent News</h2>
        <ul>
		   <li><p> [05/2022] Our paper "Cross-Resolution Person Re-Identification via Deep Group-Aware Representation Learning" was accepted by <i><b>ICPR'22 (CCF C)</b></i> </p></li>
		  
		   <li><p> [05/2022] CFP for Special Session "<a href="https://www.mdpi.com/journal/sensors/special_issues/IPAOD#info"><i><b>Image Processing and Analysis for Object Detection</b></i></a>" at the Journal of <a href="https://www.mdpi.com/journal/sensors"<i><b>Sensors</b></i></a>, 
	                              <font color="red"><strong>Deadline: October 1, 2022</strong></font> </p></li>
		   
		   <li><p> [04/2022] CFP for Special Session "<a href="https://www.journals.elsevier.com/computers-and-electrical-engineering/call-for-papers/visual-transformer-for-image-video-understanding-vsi-vti"><i><b>Visual Transformer for Image/Video Understanding (VSI-vti)</b></i></a>" 
			   at the Journal of <a href="https://www.journals.elsevier.com/computers-and-electrical-engineering"<i><b>Computers & Electrical Engineering</b></i></a>, <font color="red"><strong>Deadline: July 1, 2022</strong></font>  </p></li>
		
		   <li><p> [04/2022] I was invited to be a PC Member for CCBR 2022  </p></li>
		
		   <li><p> [04/2022] Our paper "Lightweight Bimodal Network for Single-Image Super-Resolution via Symmetric CNN and Recursive Transformer" was accepted by <i><b>IJCAI'22 (CCF A)</b></i>, with the acceptance rate to be <b>15%</b> </p></li>
		
		   <li><p> [04/2022] One co-authored paper "Multiple Degradation and Reconstruction Network for Single Image Denoising via Knowledge Distillation" was accepted by <i><b>NTIRE at CVPR'22</b></i>  </p></li>
		
		   <li><p> [03/2022] Our paper "FBSNet: A Fast Bilateral Symmetrical Network for Real-Time Semantic Segmentation" was accepted by <i><b>IEEE Transactions on Multimedia (TMM) (CCF B)</b></i> </p></li>
		
		   <li><p> [01/2022] Our paper "Leaning Compact and Representative Features for Cross-Modality Person Re-Identification" was accepted by <i><b>World Wide Web (WWW) (CCF B)</b></i> </p></li>
		
		   <li><p> [12/2021] Our paper "Feature Distillation Interaction Weighting Network for Lightweight Image Super-Resolution" was accepted by <i><b>AAAI'22 (CCF A)</b></i>  </p></li>
		
		   <li><p> [08/2021] One corresponding authored paper "JSPNet: Learning Joint Semantic & Instance Segmentation of Point Clouds via Feature Self-similarity and Cross-task Probability" was accepted by <i><b>Pattern Recognition (CCF B)</b></i> </p></li>
		
		   <li><p> [07/2021] Our paper "MSCFNet: A Lightweight Network With Multi-Scale Context Fusion for Real-Time Semantic Segmentation" was accepted by <i><b> IEEE Transactions on Intelligent Transportation Systems (CCF B) </b></i> </p></li>
		
		   <li><p> [03/2021] Our paper "Lightweight Image Super-Resolution with Multi-scale Feature Interaction Network" was accepted by <i><b>ICME'21 (CCF B) </b></i> </p></li>
		
		   <li><p> [02/2021] One co-authored paper "Graph regularized Bayesian tensor factorization based on Kronecker-Decomposable dictionary" was accepted by <i><b>Computers and Electrical Engineering</b></i> </p></li>
		   
		   <li><p> [01/2021] One co-authored paper "Short-term load forecasting based on improved GEP and abnormal load recognition" was accepted by <i><b>ACM Transactions on Internet Technology (CCF B)</b></i> </p></li>
		
		   <li><p> [11/2020] Our paper "Hierarchical Deep CNN Feature Set-Based Representation Learning for Robust Cross-Resolution Face Recognition" was accepted by <i><b>IEEE Transactions on Circuits and Systems for Video Technology (CCF B)</b></i> </p></li>
		
		   <li><p> [10/2020] Our special session titled "<a href="https://guangweigao.github.io/icme21ss.html"><i><b>Advanced Representation Learning for Robust Multimedia Image Understanding</b></i></a>" got accepted at <a href="https://2021.ieeeicme.org/"><i><b>ICME 2021</b></i></a>, with Prof. Junjun Jiang, Prof. Licheng Liu, Prof. Tao Lu, and Prof. Jingang Shi  </p></li>
		   
		   <li><p> [09/2020] One co-authored paper "Adaptive Deformable Convolutional Network" was accepted by <i><b>Neurocomputing</b></i> </p></li>
		   
		   <li><p> [09/2020] One co-authored paper "Chinese Image Captioning via Fuzzy Attention-based DenseNet-BiLSTM" was accepted by <i><b>ACM Transaction on Multimedia Computing Communication and Applications (CCF B)</b></i> </p></li>
		   
		   <li><p> [08/2020] Our paper "Robust Facial Image Super-Resolution by Kernel Locality-Constrained Coupled-Layer Regression" was accepted by <i><b>ACM Transactions on Internet Technology (CCF B)</b></i> </p></li>
		
		   <li><p> [08/2020] Our paper "Cross-resolution face recognition with pose variations via multilayer locality-constrained structural orthogonal procrustes regression" was accepted by <i><b>Information Sciences (CCF B)</b></i> </p></li>
		
		   <li><p> [07/2020] Our paper "Constructing multilayer locality-constrained matrix regression framework for noise robust face super-resolution" was accepted by <i><b>Pattern Recognition (CCF B)</b></i> </p></li>
		   
		   <li><p> [02/2020] Our paper "Multi-scale patch based representation feature learning for low-resolution face recognition" was accepted by <i><b>Applied Soft Computing</b></i> </p></li>
		   
		   <!--<li><p> I was invited to be a PC member for AISTATS 2021 </br>
		   我受邀担任AISTATS 2021程序委员会成员</p></li>		   
		   <li><p> Our group won the 3rd place of CVPR 2020 Learning from Imperfect Data (LID) challenge (Track of Weakly-supervised Object Localization)! </br>
		   团队获得CVPR 2020不完备数据竞赛弱监督目标定位项目季军！</p></li>			   		   
		   <li><p> I gave a talk at the workshop@CCDM 2020 </br>
		   我在中国数据挖掘会议“低质量数据挖掘与学习”论坛作学术报告</p></li>		   		   
		   <li><p> The invention patent "A new method of multi lane detection" has been granted! </br>
		   发明专利《一种多车道线检测新方法》获得授权！</p></li>	   
		   <li><p> I was invited to be a SPC for IJCAI 2021 </br>
		   我受邀担任IJCAI 2021高级程序委员会成员</p></li>		   
		   <li><p> I was invited to be a reviewer for JMLR </br>
		   我受邀担任国际期刊JMLR审稿人</p></li>	   
		   <li><p> The application for CCF-Tencent Open Fund has been approved! </br>
		   申请的CCF-腾讯犀牛鸟基金获批！</p></li>	   
		   <li><p>Our paper "Coupled bilinear discriminant projection for cross-view gait recognition" was selected as a ESI highly cited paper! </br>
		   论文"Coupled bilinear discriminant projection for cross-view gait recognition"被评选为ESI高被引论文（本领域世界前1%的论文）！ </p></li>	   
		   <li><p>I will serve as a reviewer for ICLR 2021! </br>
		   我受邀担任ICLR 2021审稿人. </p></li>
		   <li><p>Our paper "Learning to acquire the quality of human pose estimation" was accepted by IEEE T-CSVT! </br>		   
		   论文"Learning to acquire the quality of human pose estimation"被IEEE T-CSVT录用！ </p></li>
		   <li><p>Our paper "Multi-modal curriculum learning for semi-supervised image classification" was selected as a ESI highly cited paper! </br>
		   论文"Multi-modal curriculum learning for semi-supervised image classification"被评选为ESI高被引论文（本领域世界前1%的论文）！ </p></li>
		   <!-- <li><p>Call for application to <a href="https://www.comp.hkbu.edu.hk/v1/?page=hkpfs-info" target="_blank">HKBU - Hong Kong PhD Fellowship Scheme (HKPFS)</a>.</p></li>
		   <li><p>Oct 2019: I will give a talk <a href="https://cbs.riken.jp/en/events/theoryworkshop/" target="_blank">"Robust Deep Learning: Challenges and New Directions"</a> at<br>
		   Workshop: Theory towards Brains, Machines and Minds, Center for Brain Science, RIKEN. </p></li>
		   <li><p>Sep 2019: I will serve as a PC member for AISTATS'20. </p></li>
		   <li><p>Sep 2019: I will give a talk "Robust Deep Learning: Challenges and New Directions" at<br>
		   International Research Center for Neurointelligence, The University of Tokyo. </p></li>
		   <li><p>Sep 2019: I will co-organize ACML 2019 Challenge on <a href="https://www.4paradigm.com/competition/autowsl2019" target="_blank">AutoWSL</a><br>
		   (with Quanming Yao, Wei-Wei Tu, Isabelle Guyon, and Qiang Yang). </p></li>
		   <li><p>Sep 2019: Paper <a href="https://arxiv.org/abs/1906.00189" target="_blank">"T-Revision"</a> is accepted to NeurIPS'19. Congrats, all co-authors!</p></li>
		   <li><p>Aug 2019: I will co-organize ACML 2019 Workshop on <a href="http://www.acml-conf.org/2019/workshops/weakly-supervised/" target="_blank">Weakly-supervised Learning</a><br>
		   (with Gang Niu, Quanming Yao, Giogio Patrini, Aditya Menon, Clayton Scott and Masashi Sugiyama). </p></li>
		   <li><p>Aug 2019: I will co-organize ACML 2019 Tutorial on <a href="http://www.acml-conf.org/2019/tutorials/tsang-han/" target="_blank">Towards Noisy Supervision</a> (with Ivor W. Tsang).</p></li>
		   <li><p>Aug 2019: I will serve as a PC member for AAAI'20. </p></li>
		   <li><p>Jul 2019: I will serve as a PC member for ICLR'20. </p></li> -->
        </ul>
    </div>

 <!--   <div>
        <h2><hr><a name="research"></a>Research (研究领域)</h2>

<!-- <ul>
I am co-supervising <a href="https://bhanml.github.io/group.html" target="_blank">Research Group</a> at RIKEN-AIP.
</ul> -->

<!--<ul>
My research interests lie in machine learning, data mining, and learning-based vision problems. Particularly, I'm interested in weakly-supervised learning and its applications, such as semi-supervised learning, positive-unlabeled learning, label noise learning, partial label learning, etc.
</ul>-->

<!--<ul>
 我的研究方向主要为机器学习、数据挖掘及基于学习的计算机视觉问题。特别地，我关注弱监督学习方法及其应用，比如半监督学习、PU学习、标签噪声学习、偏标记学习等。
</ul>-->
<!-- <ul> -->
<!-- <li><p>Weakly-supervised Machine Learning: How can we train complex models robustly using weakly-supervised information?</p></li> -->
<!-- <li><p>Security, Privacy and Robustness in Machine Learning: How can we preserve the security, privacy and robustness in training complex models?</p></li> -->
<!-- <li><p>Automated Machine Learning: How can we reason about intelligent systems without human intervention?</p></li> -->
<!-- <li><p>Interdisciplinary Problems: How can we apply the above fundamental research to the healthcare domain?</p></li> -->
<!-- </ul> -->
<!-- <img src="wordcloud-beta.jpg" alt="wordcloud" /> -->
</div>

    <!-- <div> -->
        <!-- <h2><hr><a name="tutorials-workshops"></a>Workshops, Tutorials and Challenges</h2> -->
        <!-- <ul> -->
		   <!-- <li><p>ACML 2019 Workshop on <a href="http://www.acml-conf.org/2019/workshops/weakly-supervised/" target="_blank">Weakly-supervised Learning</a> (with Gang Niu, Quanming Yao, Giogio Patrini, Aditya Menon, Clayton Scott and Masashi Sugiyama).</p></li> -->
		   <!-- <li><p>ACML 2019 Tutorial on <a href="http://www.acml-conf.org/2019/tutorials/tsang-han/" target="_blank">Towards Noisy Supervision: Problems, Theories, and Algorithms</a> (with Ivor W. Tsang).</p></li> -->
		   <!-- <li><p>ACML 2019 Challenge on <a href="https://www.4paradigm.com/competition/autowsl2019" target="_blank">AutoML for Weakly-supervised Learning (AutoWSL)</a> (with Quanming Yao, Wei-Wei Tu, Isabelle Guyon, and Qiang Yang).</p></li> -->
        <!-- </ul> -->
    <!-- </div> -->



<!--    <div>
        <h2><hr><a name="talks"></a>Representative Talks</h2>
        <ul>
            <li><p>
                Co-teaching<br>
                <iframe width="230" height="150" src="https://www.youtube.com/embed/T3HNz2VXHMk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </p></li>
            <li><p>
                Masking<br>
                <iframe width="230" height="150" src="https://www.youtube.com/embed/T3HNz2VXHMk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </p></li>
            <li><p>
               Towards Robust Deep Learning. Hong Kong Baptist University, Hong Kong, 2018.12, [<a href="https://www.comp.hkbu.edu.hk/v1/?page=seminars&id=497" target="_blank">link</a>].
            </p></li>
            <li><p>
               Towards Robust Deep Learning. Fourth Paradigm Inc., China, 2018.11, [<a href="papers/slides_RDL.pdf" target="_blank">PDF</a>].
            </p></li>
            <li><p>
                When Robust Deep Learning Meets Noisy Labels. University of Tokyo, Japan, 2018.10.
            </p></li>
            <li><p>
                Robust Deep Learning with Noisy Labels. National University of Singapore, Singapore, 2018.9,
                [<a href="https://aip.riken.jp/news/nussoc_jointws/" target="_blank">link</a>].
            </p></li>
             <li><p>
                Robust Deep Learning with Noisy Labels. Nanjing University, China, 2018.9, [<a href="https://keysoftlab.nju.edu.cn/7d/0f/c1578a294159/page.htm" target="_blank">link</a>].
            </p></li>
            <li><p>
                Learning from Imperfect Supervision. Hong Kong Baptist University, Hong Kong, 2018.5.
            </p></li>
        </ul>
    </div>-->

 

<!--        <div>
        <h2><hr><a name="edu"></a>Sponsors</h2>
        <ul>
            <li><p>
               Australian Research Council (2015.2 - 2019.2)<br>
                My Ph.D. research is supported by ARC FT130100746, DP180100106 and LP150100671 (Prof. Tsang's grants).<br>
            </p></li>
            <li><p>
                Global Business College of Australia (2018.8 - 2018.9)<br>
                My KDD'18 related  research is supported by Global Business College of Australia (4,000 AUD).<br>
            </p></li>
        </ul>
    </div>-->

    <div>
    <h2><hr><a name="sponsors"></a>Sponsors</h2>
    <img src="imgjpg/nsfc.jpg" alt="NSFC" />
    <img src="imgjpg/JSED.jpg" alt="JSED" />
    <img src="imgjpg/kxjst.jpg" alt="kxjst" />
    <!-- <img src="arc-beta.jpg" alt="Australian Research Council" />
    <img src="logo-gbca-beta.jpg" alt="Global Business College of Australia" /> -->
	<!-- <img src="imgjpg/CPSF.jpg" alt="CPSF" />-->
	<!-- <img src="imgjpg/NJUPT.jpg" alt="NJUPT" />-->
	
    </div>
	

    <div>
    <h2><hr><a name="sponsors"></a>Collaborators</h2>
    Prof. <a href="http://www.patternrecognition.asia/jian/"><i><b>Jian Yang</b></i></a>  &nbsp &nbsp &nbsp
    Prof. <a href="https://www.eecs.ucf.edu/~gqi/"><i><b>Guo-Jun Qi</b></i></a>  &nbsp &nbsp &nbsp
    Prof. <a href="http://research.nii.ac.jp/~yiyu/"><i><b>Yi Yu</b></i></a>  &nbsp &nbsp &nbsp
    Prof. <a href="http://www.smartllv.com/"><i><b>Meng Yang</b></i></a>  &nbsp &nbsp &nbsp    
    Dr. <a href="https://junchenglee.com/"><i><b>Juncheng Li</b></i></a>  &nbsp &nbsp &nbsp
    </div>



    <div>
	<h2><hr><a name="acess"></a>Acess Count</h2>
	<table style="width:35%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
		  <td style="padding:25px;border:0px;width:35%;vertical-align:middle">
		    <p style="text-align:center;font-size:small;">
		     <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=cbf0ff&w=a&t=tt&d=TmuKM-GqCcXdVdOWUm7w6WWzC8tFxE8foYUjmy35CQY&co=32aaff&cmo=00b92d&cmn=ff9500'></script>
		 <!--<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=x2u3PduOONe9Td3feD9UapQ38U9IKGjYFkugvJLdXog"></script>-->
		    </p>
		  </td>
		</tr>
		</tbody></table>
     </div>

   
<!--script src="//t1.extreme-dm.com/f.js" id="eXF-bhan-0" async defer></script>
<!--Theme from <a href="https://www.cc.gatech.edu/~lsong/" target="_blank">Prof. Le Song</a>-->
</td>
</tr>
</table>
</body>
</html>
