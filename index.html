<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Guangwei Gao</title>
    <base href="https://guangweigao.github.io/">
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Guangwei Gao (高广谓)</h1><hr>
<td id="layout-menu">
	<!-- <div class="menu-item"><a href="news.html">News</a></div> -->
	<!-- <div class="menu-item"><a href="contact.html">Contact (联系方式)</a></div> -->
	<!--<div class="menu-item"><a href="codes.html">Codes</a></div>-->
	<!--<div class="menu-item"><a href="talks.html">Talks</a></div>-->
	<!--<div class="menu-item"><a href="codedata.html">Codes & Data</a></div>
        <!--<div class="menu-item"><a href="seminar.html">ML Seminar</a></div>-->
	<!--<span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>-->
	<div class="menu-item"><a href="index.html" class="current">Home</a></div>
	<!--<div class="menu-item"><a href="education.html">Education</a></div>-->
	<div class="menu-item"><a href="teaching.html">Teaching</a></div>
	<div class="menu-item"><a href="publications.html">Publications</a></div>
	<!--<div class="menu-item"><a href="patents.html">Patents</a></div>-->
	<div class="menu-item"><a href="members.html">Group Members</a></div>
        <div class="menu-item"><a href="awardstalks.html">Awards & Talks</a></div>
	<div class="menu-item"><a href="patentsservice.html">Patents & Services</a></div>
	<div class="menu-item"><a href="projects.html">Research Projects</a></div>
	<div class="menu-item"><a href="recruitement.html">Call for Students</a></div>
	<div class="menu-item"><a href="resources.html">Recommended Resources</a></div>
	<!--<div class="menu-item"><a href="icme22ss.html">ICME2022 Special Session</a></div>-->
	
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Intelligent VIsual Perception Group (IVIP Group)</h1><br>
  <!--  <p>[ <a href="#news">News</a>,
        <a href="#interest">Research Interests</a>,
        <a href="#job">Job Experience</a>,
        <a href="#edu">Education</a> ]</p>-->

    <table class="imgtable"><tr valign="top">
        <td><img src="imgjpg/ggw-photo.jpg" alt="MyPhoto" /></td>
        <td align="left">
            <p><span style="font-size: 110%"><b>Guangwei Gao (IEEE/CCF/CSIG/CAAI/CAA Senior Member)</b></span></p>
            <p>
                Professor <br>
		Institute of Advanced Technology<br>
		Nanjing University of Posts and Telecommunications<br>
		No.9, Wenyuan Road, Xianlin, Nanjing, China, 210046<br>
		<!--Postdoc Fellow (with <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a>)<br>
                <a href="https://aip.riken.jp/labs/generic_tech/imperfect_inf_learn/" target="_blank">Imperfect Information Learning Team</a><br>
                <a href="http://www.riken.jp/en/" target="_blank">RIKEN</a>
                <a href="https://aip.riken.jp/" target="_blank">Center for Advanced Intelligence Project</a> -->
            </p>
             <!--<p>
                Assistant Professor<br>
                <a href="https://www.comp.hkbu.edu.hk/v1/?page=home" target="_blank">Department of Computer Science</a><br>
                <a href="https://www.hkbu.edu.hk/eng/main/index.jsp" target="_blank">Hong Kong Baptist University</a>
            </p> -->

                E-mail:  <i><b>csggao@gmail.com</b></i> <br>
                <!--<a href="https://sites.google.com/view/guangweigao">[Google Web]</a>-->
                <a href="https://github.com/guangweigao">[Personal Github]</a> 
		<a href="https://github.com/IVIPLab">[Group Github]</a>
		<a href="https://scholar.google.com/citations?user=YD6gAw4AAAAJ&hl=zh-CN">[Google Scholar]</a> 
		<a href="https://dblp.org/pid/118/3484.html">[DBLP]</a> 
		<a href="https://guangweigao.github.io/file/ToProspectiveStudents.pdf"><font color="red"><b>[学生申请须知！！！]</b></font></a> 
				<br>
               </p>
		<i>Genius only means hard-working all one's life .—— Mendeleyer , Russian Chemist</i>
            </p>			 
				
		
        </td>
    </tr></table>
	
	
	
       <div>
        <h2><hr><a name="Brief Biography"></a>Brief Biography</h2>
        <ul>
        Guangwei Gao received his B.S. degree from Nanjing Normal University in 2009, and the Ph.D. degree in pattern recognition and intelligence systems from the Nanjing University of Science and Technology in 2014 (advised by Prof. <a href="http://www.patternrecognition.asia/jian/"><i><b><font color="blue">Jian Yang</font></b></i></a>). 
	He was a Visiting Student at the Department of Computing, The Hong Kong Polytechnic University, in 2011 and 2013, respectively (advised by Prof. <a href="https://www4.comp.polyu.edu.hk/~cslzhang/"><i><b><font color="blue">Lei Zhang</font></b></i></a>). From 2019 to 2021, he was also a Project Researcher with the National Institute of Informatics, Japan. 
	He is currently a Professor at Nanjing University of Posts and Telecommunications. His research interests include pattern recognition and computer vision. 
	He has published more than 100 scientific papers in IEEE-TIP/TCSVT/TITS/TMM/TIFS, ACM-TOIT/TOMM, CVPR, AAAI, IJCAI, PR, etc, and served as a reviewer for journals and conferences including IEEE TPAMI/TMM/TCSVT/TNNLS/TYCB, CVPR, ICCV, ECCV, AAAI, etc. 
	He is also Senior Members of IEEE/CCF/CSIG/CAAI/CAA . <a href="https://guangweigao.github.io/file/Brief-Biography-CN.pdf"><font color="blue"><strong>[中文版本]</strong></font></a>
</ul>
  </div>
	
	
	<div>
        <h2><hr><a name="Research topics"></a>Research Interests</h2>
        <ul>
           My research interests lie in machine learning, pattern recognition, and learning-based vision problems. Particularly, I'm interested in heterogeneous image analysis (recognition, super-resolution), 
		efficient deep neural network design (used for semantic segmentation, super-resolution), and processing of cross-modality visual data (person re-identification). <a href="https://guangweigao.github.io/file/Research-Interests-CN.pdf"><font color="blue"><strong>[中文版本]</strong></font></a><br>  
        </ul>			 
    </div>
	
	
	<!-- <div>
        <h2><a name="Education"></a>Education</h2>
        <ul>
              <li><p>09/2005-07/2009,  School of Math and Computer Science and Engineering, Nanjing Normal University, 
                  B.S. in Information and Computation Science</p></li>
              <li><p>09/2009-06/2014,  School of Computer Science and Engineering, Nanjing University of Science and Technology, Ph.D. in Pattern Recognition and Intelligence Systems, supervised by Prof. <a href="http://www.patternrecognition.asia/jian/"><i><b>Jian Yang</b></i></a></p></li>
              <li><p>03/2011-09/2011, 02/2013-08/2013, Visiting Student,  Department of Computing, The Hong Kong Polytechnic University, supervised by Prof. <a href="https://www4.comp.polyu.edu.hk/~cslzhang/"><i><b>Lei Zhang</b></i></a></p></li>
</ul>
  </div>-->	
	
	
	<!--<div>
        <h2><hr><a name="Research Experience"></a>Research Experience</h2>
        <ul>
		<li><p> 11/2014- 11/2016, Postdoctoral Researcher, Nanjing University of Posts and Telecommunications, China </p></li>
		<li><p> 07/2014-06/2017, Assistant Professor, Institute of Advanced Technology, 
	Nanjing University of Posts and Telecommunications, China </p></li>
		<li><p> 07/2017-present, Associate Professor, Institute of Advanced Technology, 
	Nanjing University of Posts and Telecommunications, China </p></li>
                <li><p> 04/2019-03/2021, Project Researcher, National Institute of Informatics, Tokyo, Japan </p></li>	
        </ul>
    </div>-->
	
	
	
 <div>
        <h2><hr><a name="news"></a>Recent News</h2>
        <ul>

		   <li><p> [07/2025] I will serve as a PC Member for <a href="https://aaai.org/conference/aaai/aaai-26/"><i><b>AAAI 2026</b></i></a>  </p></li>
		
		   <li><p> [07/2025] Our paper "Cross Paradigm Representation and Alignment Transformer for Image Deraining" was accepted by <i><b>ACMMM'25 (CCF-A)</b></i> </p></li>

		   <li><p> [07/2025] One paper "AEA-FIRM: Adaptive Elastic Alignment with Fine-Grained Representation Mining for Text-based Aerial Pedestrian Retrieval" was accepted by <i><b>TCSVT (CCF-B)</b></i> </p></li>
		
		   <li><p> [06/2025] Our paper "ReviveDiff: A Universal Diffusion Model for Restoring Images in Adverse Weather Conditions" was accepted by <i><b>IEEE TIP (CCF-A)</b></i> </p></li>
		
		   <li><p> [05/2025] One paper (1 TITS)  is selected as <font color="red"><i><b>Highly Cited Paper</b></i></font> in the latest issue of ESI Index, 2025 </p></li>
		
		   <li><p> [04/2025] I was elevated to the grade of <i><b> CAA Senior Member</b></i>  </p></li>
		
		   <li><p> [04/2025] 论文 "融合多光流与KAN的微表情识别方法" 被<i><b>《中国图象图形学报》</b></i> 录用</p></li>
		
		   <li><p> [03/2025] <font color="red"><i><b>Three</b></i></font> papers (DMSR,Fraesormer,MambaMIC) were accepted by <i><b>ICME'25 (CCF-B)</b></i> </p></li>
		   
		   <li><p> [03/2025] One paper "Balanced multi-modal learning with Hierarchical Fusion for fake news detection" was accepted by <i><b>PR (CCF-B)</b></i> </p></li>
		   
		   <li><p> [02/2025] One paper "DORNet: A Degradation Oriented and Regularized Network for Blind Depth Super-Resolution" was accepted by <i><b>CVPR'25 (CCF-A)</b></i> </p></li>
		
		   <li><p> [01/2025] Three papers (2 TMM, 1 TIP)  are selected as <font color="red"><i><b>Highly Cited Papers</b></i></font> in the latest issue of ESI Index, 2025 </p></li>
		
		   <li><p> [12/2024] Our paper "OCTAMamba: A State-Space Model Approach for Precision OCTA Vasculature Segmentation" was accepted by <i><b>ICASSP'25 (CCF-B)</b></i> </p></li>
		
		   <li><p> [12/2024] I was elevated to the grade of <i><b> CAAI Senior Member</b></i>  </p></li>

		   <li><p> [09/2024] Our paper "Efficient Image Super-Resolution with Feature Interaction Weighted Hybrid Network" was accepted by <i><b>IEEE TMM (CCF-B)</b></i> </p></li>

		   <li><p> [09/2024] Our paper "An Efficient Feature Reuse Distillation Network for Lightweight Image Super-Resolution" was accepted by <i><b>CVIU (CCF-B)</b></i> </p></li>
		
		   <li><p> [09/2024] Our paper "Lednet: A Lightweight Encoder-Decoder Network for Real-Time Semantic Segmentation" (ICIP 2019) wins <font color="red"><i><b>ICIP'24 Most Influential Paper Award</b></i></font> </p></li>
		
		   <li><p> [08/2024] Our paper "Efficient Dual-branch Information Interaction Network for Lightweight Image Super-Resolution" was accepted by <i><b>IEEE TIM (IF:5.6)</b></i> </p></li>
		
		   <li><p> [06/2024] Our paper "HAFormer: Unleashing the Power of Hierarchy-Aware Features for Lightweight Semantic Segmentation" was accepted by <i><b>IEEE TIP (CCF-A)</b></i> </p></li>

                   <li><p> [06/2024] I will serve as a PC Member for <a href="https://aaai.org/conference/aaai/aaai-25/"><i><b>AAAI 2025</b></i></a>  </p></li>
		
		   <li><p> [05/2024] I was elevated to the grade of <i><b> CSIG Senior Member</b></i>  </p></li>
		
		   <li><p> [05/2024] One paper "EWT: Efficient Wavelet-Transformer for Single Image Denoising" was accepted by <i><b>Neural Networks (CCF-B)</b></i> </p></li>
		  
		   <li><p> [04/2024] One paper "A Systematic Survey of Deep Learning-based Single-Image Super-Resolution" was accepted by <i><b>ACM Computing Surveys (IF:16.6)</b></i> </p></li>
		
		   <li><p> [02/2024] Our paper "Boundary-guided Lightweight Semantic Segmentation with Multi-scale Semantic Context" was accepted by <i><b>IEEE TMM (CCF-B)</b></i> </p></li>
		
		   <li><p> [12/2023] One paper "A Fine-Grained Orthodontics Segmentation Dataset and Benchmark for 3D Intraoral Scans" was accepted by <i><b>Computers in Biology and Medicine (IF:7.7)</b></i> </p></li>
		
		   <li><p> [11/2023] One paper "Efficient Image Classification via Structured Low-rank Matrix Factorization Regression" was accepted by <i><b>IEEE TIFS (CCF-A)</b></i> </p></li>
		
		   <li><p> [11/2023] I will serve as a PC Member for <a href="https://brain.korea.ac.kr/icprai2024/"><i><b>ICPRAI 2024</b></i></a>  </p></li>
		
		   <li><p>[10/2023] ICIG2023专题论坛"<a href="https://mp.weixin.qq.com/s/foHxlYdUXCHXaoDeP1rLig"><i><b>多模态数据感知与学习</b></i></a>" 成功举办</p></li>
		
		   <li><p> [09/2023] Our paper "FBSNet: A Fast Bilateral Symmetrical Network for Real-Time Semantic Segmentation" was labeled as an <i><b>ESI Highly Cited Paper</b></i> </p></li>
		
		   <li><p> [09/2023] 论文 "深度学习在口腔医学影像中的应用与挑战" 被<i><b>《中国图象图形学报》</b></i> 录用</p></li>
		  
		   <li><p> [08/2023] I will serve as a PC Member for <a href="https://www.bigmm.org/"><i><b>BigMM 2023</b></i></a>  </p></li>
		
		   <li><p> [08/2023] Our paper "MFFNet: A Multi-channel Feature Fusion Network for Face Super-Resolution" was accepted by <i><b>ACPR'23 </b></i> </p></li>
		
		   <li><p> [04/2023] Our paper "Cross-receptive Focused Inference Network for Lightweight Image Super-Resolution" was accepted by <i><b>IEEE TMM (CCF-B)</b></i> </p></li>   
		
		   <li><p> [04/2023] One review paper "Review on Quaternion-based Color Image Processing Methods" was accepted by <i><b>Mathematics (JCR Q1)</b></i> </p></li>
		
		   <li><p> [04/2023] CFP for Workshop "<a href="https://ericlab.org/acpr2023/workshops/"><i><b>Representation Learning for Computer Vision and Pattern Recognition</b></i></a>" at the Conference of <a href="https://ericlab.org/acpr2023/"<i><b>ACPR 2023</b></i></a>, 
	                              <font color="red"><strong>Deadline: June 15, 2023</strong></font> </p></li>
		
		   <li><p> [03/2023] Our paper "CTCNet: A CNN-Transformer Cooperation Network for Face Image Super-Resolution" was accepted by <i><b>IEEE TIP (CCF-A)</b></i> </p></li>   
		
		   <li><p> [02/2023] Our paper "Lightweight Real-time Semantic Segmentation Network with Efficient Transformer and CNN" was accepted by <i><b>IEEE TITS (CCF-B)</b></i> </p></li>   
		
		   <li><p> [02/2023] One paper "PFT-SSR: Parallax Fusion Transformer for Stereo Image Super-Resolution" was accepted by <i><b>ICASSP'23 (CCF-B)</b></i> </p></li>
		  
		   <li><p> [01/2023] Our paper "JDSR-GAN: Constructing An Efficient Joint Learning Network for Masked Face Super-Resolution" was accepted by <i><b>IEEE TMM (CCF-B)</b></i> </p></li> 
		
		   <li><p> [11/2022] Our paper "Occluded Visible-infrared Person Re-identification" was accepted by <i><b>IEEE TMM (CCF-B)</b></i> </p></li>   
		
		   <li><p> [11/2022] Our paper "Semi-supervised Cross-modal Hashing Via Modality-specific and Cross-modal Graph Convolutional Networks" was accepted by <i><b>Pattern Recognition (CCF-B)</b></i> </p></li>   
		
		   <li><p> [10/2022] Our paper "Lightweight Feature De-Redundancy and Self-Calibration Network for Efficient Image Super-Resolution" was accepted by <i><b>ACM TOMM (CCF-B)</b></i> </p></li>
		
		   <li><p> [09/2022] CFP for Special Session "<a href="https://www.mdpi.com/journal/mathematics/special_issues/V5G28PQF0B"><i><b>Representation Learning for Computer Vision and Pattern Recognition</b></i></a>" at the Journal of <a href="https://www.mdpi.com/journal/mathematics"<i><b>Mathematics</b></i></a>, 
	                              <font color="red"><strong>Deadline: February 28, 2024</strong></font> </p></li>
		
		   <li><p> [08/2022] I will serve as a PC Member for <a href="https://aaai.org/Conferences/AAAI-23/"><i><b>AAAI 2023</b></i></a>  </p></li>
		
		   <li><p> [07/2022] Our paper "Multi-feature Sparse Similar Representation for Person Identification" was accepted by <i><b>Pattern Recognition (CCF-B)</b></i> </p></li>
		
		   <li><p> [07/2022] Our paper "Context-Patch Representation Learning with Adaptive Neighbor Embedding For Robust Face Image SuperResolution" was accepted by <i><b>IEEE TMM (CCF-B)</b></i> </p></li>
		
		   <li><p> [07/2022] I will serve as a Session Chair for <a href="https://2022.ieeeicme.org/"><i><b>ICME 2022</b></i></a>  </p></li>
		   
		   <li><p> [06/2022] I was elevated to the grade of <i><b> IEEE Senior Member</b></i>  </p></li>
		
		   <li><p> [06/2022] I will serve as a PC Member for <a href="https://www.bigmm.org/"><i><b>BigMM 2022</b></i></a>  </p></li>
		
		   <li><p> [05/2022] Our paper "Cross-Resolution Person Re-Identification via Deep Group-Aware Representation Learning" was accepted by <i><b>ICPR'22 (CCF-C)</b></i> </p></li>
		  
		   <li><p> [05/2022] CFP for Special Session "<a href="https://www.mdpi.com/journal/sensors/special_issues/IPAOD#info"><i><b>Image Processing and Analysis for Object Detection</b></i></a>" at the Journal of <a href="https://www.mdpi.com/journal/sensors"<i><b>Sensors</b></i></a>, 
	                              <font color="red"><strong>Deadline: October 1, 2022</strong></font> </p></li>
		   
		   <li><p> [04/2022] CFP for Special Session "<a href="https://www.journals.elsevier.com/computers-and-electrical-engineering/call-for-papers/visual-transformer-for-image-video-understanding-vsi-vti"><i><b>Visual Transformer for Image/Video Understanding (VSI-vti)</b></i></a>" 
			   at the Journal of <a href="https://www.journals.elsevier.com/computers-and-electrical-engineering"<i><b>Computers & Electrical Engineering</b></i></a>, <font color="red"><strong>Deadline: July 1, 2022</strong></font>  </p></li>
		
		   <li><p> [04/2022] I will serve as a PC Member for <a href="https://ccbr99.cn/"><i><b>CCBR 2022</b></i></a>  </p></li>
		
		   <li><p> [04/2022] Our paper "Lightweight Bimodal Network for Single-Image Super-Resolution via Symmetric CNN and Recursive Transformer" was accepted by <i><b>IJCAI'22 (CCF-A)</b></i>, with the acceptance rate to be <b>15%</b> </p></li>
		
		   <li><p> [04/2022] Our paper "Multiple Degradation and Reconstruction Network for Single Image Denoising via Knowledge Distillation" was accepted by <i><b>NTIRE at CVPR'22</b></i>  </p></li>
		
		   <li><p> [03/2022] Our paper "FBSNet: A Fast Bilateral Symmetrical Network for Real-Time Semantic Segmentation" was accepted by <i><b>IEEE TMM (CCF-B)</b></i> </p></li>
		
		   <li><p> [01/2022] Our paper "Leaning Compact and Representative Features for Cross-Modality Person Re-Identification" was accepted by <i><b>World Wide Web (WWW) (CCF-B)</b></i> </p></li>
		
		   <li><p> [12/2021] Our paper "Feature Distillation Interaction Weighting Network for Lightweight Image Super-Resolution" was accepted by <i><b>AAAI'22 (CCF-A)</b></i>  </p></li>
		
		   <li><p> [08/2021] Our paper "JSPNet: Learning Joint Semantic & Instance Segmentation of Point Clouds via Feature Self-similarity and Cross-task Probability" was accepted by <i><b>Pattern Recognition (CCF-B)</b></i> </p></li>
		
		   <li><p> [07/2021] Our paper "MSCFNet: A Lightweight Network With Multi-Scale Context Fusion for Real-Time Semantic Segmentation" was accepted by <i><b> IEEE TITS (CCF-B) </b></i> </p></li>
		
		   <li><p> [03/2021] Our paper "Lightweight Image Super-Resolution with Multi-scale Feature Interaction Network" was accepted by <i><b>ICME'21 (CCF-B) </b></i> </p></li>
		
		   <li><p> [02/2021] Our paper "Graph regularized Bayesian tensor factorization based on Kronecker-Decomposable dictionary" was accepted by <i><b>Computers and Electrical Engineering</b></i> </p></li>
		   
		   <li><p> [01/2021] Our paper "Short-term load forecasting based on improved GEP and abnormal load recognition" was accepted by <i><b>ACM TOIT (CCF-B)</b></i> </p></li>
		
		   <li><p> [11/2020] Our paper "Hierarchical Deep CNN Feature Set-Based Representation Learning for Robust Cross-Resolution Face Recognition" was accepted by <i><b>IEEE TCSVT (CCF-B)</b></i> </p></li>
		
		   <li><p> [10/2020] Our special session titled "<a href="https://guangweigao.github.io/icme21ss.html"><i><b>Advanced Representation Learning for Robust Multimedia Image Understanding</b></i></a>" got accepted at <a href="https://2021.ieeeicme.org/"><i><b>ICME 2021</b></i></a>, with Prof. Junjun Jiang, Prof. Licheng Liu, Prof. Tao Lu, and Prof. Jingang Shi  </p></li>
		   
		   <li><p> [09/2020] Our paper "Adaptive Deformable Convolutional Network" was accepted by <i><b>Neurocomputing</b></i> </p></li>
		   
		   <li><p> [09/2020] Our paper "Chinese Image Captioning via Fuzzy Attention-based DenseNet-BiLSTM" was accepted by <i><b>ACM TOMM (CCF-B)</b></i> </p></li>
		   
		   <li><p> [08/2020] Our paper "Robust Facial Image Super-Resolution by Kernel Locality-Constrained Coupled-Layer Regression" was accepted by <i><b>ACM TOIT (CCF-B)</b></i> </p></li>
		
		   <li><p> [08/2020] Our paper "Cross-resolution face recognition with pose variations via multilayer locality-constrained structural orthogonal procrustes regression" was accepted by <i><b>Information Sciences (CCF-B)</b></i> </p></li>
		
		   <li><p> [07/2020] Our paper "Constructing multilayer locality-constrained matrix regression framework for noise robust face super-resolution" was accepted by <i><b>Pattern Recognition (CCF-B)</b></i> </p></li>
		   
		   <li><p> [02/2020] Our paper "Multi-scale patch based representation feature learning for low-resolution face recognition" was accepted by <i><b>Applied Soft Computing</b></i> </p></li>
		   
		   <!--<li><p> I was invited to be a PC member for AISTATS 2021 </br>
		   我受邀担任AISTATS 2021程序委员会成员</p></li>		   
		   <li><p> Our group won the 3rd place of CVPR 2020 Learning from Imperfect Data (LID) challenge (Track of Weakly-supervised Object Localization)! </br>
		   团队获得CVPR 2020不完备数据竞赛弱监督目标定位项目季军！</p></li>			   		   
		   <li><p> I gave a talk at the workshop@CCDM 2020 </br>
		   我在中国数据挖掘会议“低质量数据挖掘与学习”论坛作学术报告</p></li>		   		   
		   <li><p> The invention patent "A new method of multi lane detection" has been granted! </br>
		   发明专利《一种多车道线检测新方法》获得授权！</p></li>	   
		   <li><p> I was invited to be a SPC for IJCAI 2021 </br>
		   我受邀担任IJCAI 2021高级程序委员会成员</p></li>		   
		   <li><p> I was invited to be a reviewer for JMLR </br>
		   我受邀担任国际期刊JMLR审稿人</p></li>	   
		   <li><p> The application for CCF-Tencent Open Fund has been approved! </br>
		   申请的CCF-腾讯犀牛鸟基金获批！</p></li>	   
		   <li><p>Our paper "Coupled bilinear discriminant projection for cross-view gait recognition" was selected as a ESI highly cited paper! </br>
		   论文"Coupled bilinear discriminant projection for cross-view gait recognition"被评选为ESI高被引论文（本领域世界前1%的论文）！ </p></li>	   
		   <li><p>I will serve as a reviewer for ICLR 2021! </br>
		   我受邀担任ICLR 2021审稿人. </p></li>
		   <li><p>Our paper "Learning to acquire the quality of human pose estimation" was accepted by IEEE T-CSVT! </br>		   
		   论文"Learning to acquire the quality of human pose estimation"被IEEE T-CSVT录用！ </p></li>
		   <li><p>Our paper "Multi-modal curriculum learning for semi-supervised image classification" was selected as a ESI highly cited paper! </br>
		   论文"Multi-modal curriculum learning for semi-supervised image classification"被评选为ESI高被引论文（本领域世界前1%的论文）！ </p></li>
		   <!-- <li><p>Call for application to <a href="https://www.comp.hkbu.edu.hk/v1/?page=hkpfs-info" target="_blank">HKBU - Hong Kong PhD Fellowship Scheme (HKPFS)</a>.</p></li>
		   <li><p>Oct 2019: I will give a talk <a href="https://cbs.riken.jp/en/events/theoryworkshop/" target="_blank">"Robust Deep Learning: Challenges and New Directions"</a> at<br>
		   Workshop: Theory towards Brains, Machines and Minds, Center for Brain Science, RIKEN. </p></li>
		   <li><p>Sep 2019: I will serve as a PC member for AISTATS'20. </p></li>
		   <li><p>Sep 2019: I will give a talk "Robust Deep Learning: Challenges and New Directions" at<br>
		   International Research Center for Neurointelligence, The University of Tokyo. </p></li>
		   <li><p>Sep 2019: I will co-organize ACML 2019 Challenge on <a href="https://www.4paradigm.com/competition/autowsl2019" target="_blank">AutoWSL</a><br>
		   (with Quanming Yao, Wei-Wei Tu, Isabelle Guyon, and Qiang Yang). </p></li>
		   <li><p>Sep 2019: Paper <a href="https://arxiv.org/abs/1906.00189" target="_blank">"T-Revision"</a> is accepted to NeurIPS'19. Congrats, all co-authors!</p></li>
		   <li><p>Aug 2019: I will co-organize ACML 2019 Workshop on <a href="http://www.acml-conf.org/2019/workshops/weakly-supervised/" target="_blank">Weakly-supervised Learning</a><br>
		   (with Gang Niu, Quanming Yao, Giogio Patrini, Aditya Menon, Clayton Scott and Masashi Sugiyama). </p></li>
		   <li><p>Aug 2019: I will co-organize ACML 2019 Tutorial on <a href="http://www.acml-conf.org/2019/tutorials/tsang-han/" target="_blank">Towards Noisy Supervision</a> (with Ivor W. Tsang).</p></li>
		   <li><p>Aug 2019: I will serve as a PC member for AAAI'20. </p></li>
		   <li><p>Jul 2019: I will serve as a PC member for ICLR'20. </p></li> -->
        </ul>
    </div>

 <!--   <div>
        <h2><hr><a name="research"></a>Research (研究领域)</h2>

<!-- <ul>
I am co-supervising <a href="https://bhanml.github.io/group.html" target="_blank">Research Group</a> at RIKEN-AIP.
</ul> -->

<!--<ul>
My research interests lie in machine learning, data mining, and learning-based vision problems. Particularly, I'm interested in weakly-supervised learning and its applications, such as semi-supervised learning, positive-unlabeled learning, label noise learning, partial label learning, etc.
</ul>-->

<!--<ul>
 我的研究方向主要为机器学习、数据挖掘及基于学习的计算机视觉问题。特别地，我关注弱监督学习方法及其应用，比如半监督学习、PU学习、标签噪声学习、偏标记学习等。
</ul>-->
<!-- <ul> -->
<!-- <li><p>Weakly-supervised Machine Learning: How can we train complex models robustly using weakly-supervised information?</p></li> -->
<!-- <li><p>Security, Privacy and Robustness in Machine Learning: How can we preserve the security, privacy and robustness in training complex models?</p></li> -->
<!-- <li><p>Automated Machine Learning: How can we reason about intelligent systems without human intervention?</p></li> -->
<!-- <li><p>Interdisciplinary Problems: How can we apply the above fundamental research to the healthcare domain?</p></li> -->
<!-- </ul> -->
<!-- <img src="wordcloud-beta.jpg" alt="wordcloud" /> -->
</div>

    <!-- <div> -->
        <!-- <h2><hr><a name="tutorials-workshops"></a>Workshops, Tutorials and Challenges</h2> -->
        <!-- <ul> -->
		   <!-- <li><p>ACML 2019 Workshop on <a href="http://www.acml-conf.org/2019/workshops/weakly-supervised/" target="_blank">Weakly-supervised Learning</a> (with Gang Niu, Quanming Yao, Giogio Patrini, Aditya Menon, Clayton Scott and Masashi Sugiyama).</p></li> -->
		   <!-- <li><p>ACML 2019 Tutorial on <a href="http://www.acml-conf.org/2019/tutorials/tsang-han/" target="_blank">Towards Noisy Supervision: Problems, Theories, and Algorithms</a> (with Ivor W. Tsang).</p></li> -->
		   <!-- <li><p>ACML 2019 Challenge on <a href="https://www.4paradigm.com/competition/autowsl2019" target="_blank">AutoML for Weakly-supervised Learning (AutoWSL)</a> (with Quanming Yao, Wei-Wei Tu, Isabelle Guyon, and Qiang Yang).</p></li> -->
        <!-- </ul> -->
    <!-- </div> -->



<!--    <div>
        <h2><hr><a name="talks"></a>Representative Talks</h2>
        <ul>
            <li><p>
                Co-teaching<br>
                <iframe width="230" height="150" src="https://www.youtube.com/embed/T3HNz2VXHMk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </p></li>
            <li><p>
                Masking<br>
                <iframe width="230" height="150" src="https://www.youtube.com/embed/T3HNz2VXHMk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </p></li>
            <li><p>
               Towards Robust Deep Learning. Hong Kong Baptist University, Hong Kong, 2018.12, [<a href="https://www.comp.hkbu.edu.hk/v1/?page=seminars&id=497" target="_blank">link</a>].
            </p></li>
            <li><p>
               Towards Robust Deep Learning. Fourth Paradigm Inc., China, 2018.11, [<a href="papers/slides_RDL.pdf" target="_blank">PDF</a>].
            </p></li>
            <li><p>
                When Robust Deep Learning Meets Noisy Labels. University of Tokyo, Japan, 2018.10.
            </p></li>
            <li><p>
                Robust Deep Learning with Noisy Labels. National University of Singapore, Singapore, 2018.9,
                [<a href="https://aip.riken.jp/news/nussoc_jointws/" target="_blank">link</a>].
            </p></li>
             <li><p>
                Robust Deep Learning with Noisy Labels. Nanjing University, China, 2018.9, [<a href="https://keysoftlab.nju.edu.cn/7d/0f/c1578a294159/page.htm" target="_blank">link</a>].
            </p></li>
            <li><p>
                Learning from Imperfect Supervision. Hong Kong Baptist University, Hong Kong, 2018.5.
            </p></li>
        </ul>
    </div>-->

 

<!--        <div>
        <h2><hr><a name="edu"></a>Sponsors</h2>
        <ul>
            <li><p>
               Australian Research Council (2015.2 - 2019.2)<br>
                My Ph.D. research is supported by ARC FT130100746, DP180100106 and LP150100671 (Prof. Tsang's grants).<br>
            </p></li>
            <li><p>
                Global Business College of Australia (2018.8 - 2018.9)<br>
                My KDD'18 related  research is supported by Global Business College of Australia (4,000 AUD).<br>
            </p></li>
        </ul>
    </div>-->


    <div>
    <h2><hr><a name="sponsors"></a>Collaborators</h2>
    Prof. <a href="http://www.patternrecognition.asia/jian/"><i><b>Jian Yang</b></i></a>  &nbsp &nbsp &nbsp
    Prof. <a href="http://maple-lab.net/gqi/"><i><b>Guo-Jun Qi</b></i></a>  &nbsp &nbsp &nbsp
    Prof. <a href="https://home.hiroshima-u.ac.jp/yiyu/index.html"><i><b>Yi Yu</b></i></a>  &nbsp &nbsp &nbsp
    Prof. <a href="http://www.smartllv.com/"><i><b>Meng Yang</b></i></a>  &nbsp &nbsp &nbsp    
    Prof. <a href="https://ericlab.org/"><i><b>Huimin Lu</b></i></a>  &nbsp &nbsp &nbsp   
    Prof. <a href="https://www.fst.um.edu.mo/personal/jtzhou/"><i><b>Jiantao Zhou</b></i></a>  &nbsp &nbsp &nbsp 
    Prof. <a href="https://www.ee.nthu.edu.tw/cwlin/"><i><b>Chia-Wen Lin</b></i></a>  &nbsp &nbsp &nbsp 
    Dr. <a href="https://junchenglee.com/"><i><b>Juncheng Li</b></i></a>  &nbsp &nbsp &nbsp
    </div>


    <div>
    <h2><hr><a name="sponsors"></a>Sponsors</h2>
    <img src="imgjpg/nsfc.jpg" alt="NSFC" />
    <img src="imgjpg/JSED.jpg" alt="JSED" />
    <img src="imgjpg/kxjst.jpg" alt="kxjst" />
    <!-- <img src="arc-beta.jpg" alt="Australian Research Council" />
    <img src="logo-gbca-beta.jpg" alt="Global Business College of Australia" /> -->
	<!-- <img src="imgjpg/CPSF.jpg" alt="CPSF" />-->
	<!-- <img src="imgjpg/NJUPT.jpg" alt="NJUPT" />-->
	
    </div>
	





    <div>
	<h2><hr><a name="acess"></a>Acess Count</h2>
	<table style="width:40%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
		  <td style="padding:25px;border:0px;width:40%;vertical-align:middle">
		    <p style="text-align:center;font-size:small;">
		     <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=cbf0ff&w=a&t=tt&d=TmuKM-GqCcXdVdOWUm7w6WWzC8tFxE8foYUjmy35CQY&co=32aaff&cmo=00b92d&cmn=ff9500'></script>
		 <!--<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=x2u3PduOONe9Td3feD9UapQ38U9IKGjYFkugvJLdXog"></script>-->
		    </p>
		  </td>
		</tr>
		</tbody></table>
     </div>

   
<!--script src="//t1.extreme-dm.com/f.js" id="eXF-bhan-0" async defer></script>
<!--Theme from <a href="https://www.cc.gatech.edu/~lsong/" target="_blank">Prof. Le Song</a>-->
</td>
</tr>
</table>
</body>
</html>
